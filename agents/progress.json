{
  "issues": [
    {
      "id": 71,
      "name": "Dev HTTP Runner: Invoke Any Endpoint in a Worker Image via curl (Local Outputs)",
      "description": "Add a dev-only HTTP mode to python-gen-worker so a built worker image can be run locally and invoked with one-off HTTP requests (e.g. via curl), without standing up gen-orchestrator.\n\nGoals:\n- Start the container, mount a local output directory, then invoke any discovered endpoint/function with arbitrary JSON input.\n- All output files must be written to a mounted local directory (no Cozy Hub file API required).\n- Model weights should load on-demand during the first request (works today), but the dev server should also support explicit prefetch/warmup to avoid timeouts.\n\nNon-goals (v1):\n- Replacing the production scheduler protocol.\n- Matching every orchestrator behavior (autoscaling, queueing, JWT auth, etc.).\n\nKey design point:\n- In prod, the orchestrator instructs the worker via gRPC and provides per-run file capability tokens. In dev HTTP mode, we run the same function invocation engine in-process and swap the file backend to local-disk writes.\n",
      "tasks": [
        "[ ] Define dev HTTP API contract\n    - `POST /v1/run/{function_name}` JSON body -> JSON response\n    - Default bind: 127.0.0.1; configurable `--listen`\n    - Optional: `GET /v1/status` returns discovered functions + model cache status (disk/vram)\n    - Model control endpoints (mirror a subset of gRPC codepaths):\n      - `POST /v1/models/prefetch` body: `{ \"models\": [\"cozy:...\",\"hf:...\"], \"localize\": true|false }`\n      - `POST /v1/models/load` body: `{ \"model_id\": \"...\" }` (VRAM load)\n      - `POST /v1/models/unload` body: `{ \"model_id\": \"...\" }` (VRAM unload)\n      - `GET /v1/models/status` returns disk/vram/downloading + mount backend info\n    - Optional: `POST /v1/warmup/{function_name}` helper (forces pipeline init + GPU load)",
        "[ ] Implement local file backend for ActionContext\n    - Add a dev/local mode that makes `ctx.save_*` write under a configured output dir (e.g. `/outputs`)\n    - Preserve existing `runs/{run_id}/outputs/...` ref rules\n    - Return `Asset(local_path=...)` and stable metadata (mime/size/sha256) without any HTTP calls",
        "[ ] Implement dev HTTP server entrypoint\n    - MUST be dev-only: an explicit subcommand (`gen-worker dev serve-http`), never started by default in production worker images\n    - Add `gen-worker dev serve-http` (or `python -m gen_worker.testing.http_runner`)\n    - Load user modules from `cozy.toml main` (or baked discovery manifest.json if present)\n    - Reuse existing signature decoding + injection + model downloader behavior\n    - For incremental functions: return collected deltas (v1) or stream via SSE (optional)",
        "[ ] Implement model prefetch/load/unload/warmup behavior\n    - Prefetch downloads into `WORKER_MODEL_CACHE_DIR` (shared cache) and never into the local NVMe cache only\n    - Do NOT call `_handle_*` gRPC handlers directly (they assume a live scheduler stream). Instead, refactor/reuse the shared underlying helpers used by those handlers.\n    - Mirror the gRPC semantics where possible:\n      - load -> same core logic as `LoadModelCommand` (VRAM load)\n      - unload -> same core logic as `UnloadModelCommand` (VRAM unload)\n      - prefetch -> reuse the model downloader + model_cache marking used in startup prefetch\n    - Refactor minimal shared helpers so HTTP mode does not require an active gRPC stream (no `_send_message` dependency)\n    - Warmup is best-effort: run once to force pipeline init + GPU load\n    - Report timings using the existing metrics collector (stdout logs + optional JSON response fields)",
        "[ ] Docs + examples\n    - Document a canonical local workflow:\n      - `docker run --gpus all -p 8081:8081 -v $(pwd)/out:/outputs <img> gen-worker dev serve-http --listen 0.0.0.0:8081`\n      - `curl -X POST localhost:8081/v1/run/generate -d '{...}'`\n      - `curl -X POST localhost:8081/v1/models/prefetch -d '{\"models\":[\"hf:...\"]}'`\n      - `curl -X POST localhost:8081/v1/models/load -d '{\"model_id\":\"hf:...\"}'`\n      - `curl -X POST localhost:8081/v1/models/unload -d '{\"model_id\":\"hf:...\"}'`\n    - Ensure outputs land under the mounted directory and include a returned `local_path`",
        "[ ] Tests\n    - Unit test local file backend behavior for `ctx.save_*`\n    - Unit test model control endpoints call the right shared helpers (prefetch/load/unload)\n    - Minimal HTTP handler tests (invoke route returns 200 + writes output)"
      ],
      "completed": false
    },
    {
      "id": 72,
      "name": "Payload Chooses Repo By Short Key (pyproject.toml) + Manifest Metadata for Orchestrator Routing",
      "description": "Intended contract: a client payload can select a repo by a short string (e.g. `\"model\": \"sd15\"`) and that short string maps to a canonical Cozy repo ref declared ahead of time in `pyproject.toml` under `[tool.cozy.models]` (short-key -> `cozy:owner/repo[:tag][#component]`).\n\nToday, python-gen-worker supports signature-driven injection from payload via `Annotated[..., ModelRef(ModelRefSource.PAYLOAD, \"field_name\")]`, and resolves the chosen short key through the release-provided short-key mapping (legacy field name: `model_id_by_key`).\n\nWhat is missing for end-to-end cache-aware routing is making this contract explicit and exportable:\n- PAYLOAD values must be *keys*, not arbitrary refs\n- The orchestrator must know which payload fields select repos so it can compute required repo refs at submit-time",
      "tasks": [
        "[x] Enforce short-key semantics for ModelRef(PAYLOAD, ...)\n    - Require the payload value is a key present in the release short-key mapping (from `[tool.cozy.models]`)\n    - Unknown key: fail with a clear safe validation error (bounded list of allowed keys)\n    - Keep ModelRef(RELEASE, ...) behavior unchanged",
        "[x] Manifest metadata for orchestrator routing\n    - In `discover.py`, include which payload fields are repo selectors for each function\n    - Example: `payload_repo_selectors: [{\"field\":\"model\",\"kind\":\"short_key\"}]`\n    - Keep `injection_json` as the source of truth; this is a stable convenience for schedulers",
        "[x] Clarify manifest semantics\n    - `[tool.cozy.models]` defines the complete allowlisted keyspace and the repo ref each key maps to\n    - Ensure components (`#unet`, etc.) are representable in the ref value",
        "[x] Docs\n    - Show the pattern end-to-end: `[tool.cozy.models]` + payload short-key + `ModelRef(PAYLOAD, ...)`\n    - Document that direct repo refs in payload are not supported unless explicitly opted-in (future)",
        "[x] Tests\n    - Unit tests for PAYLOAD model selection: unknown key, known key, invalid types\n    - Discover-manifest test: `payload_repo_selectors` emitted when PAYLOAD injections exist"
      ],
      "completed": false
    },
    {
      "id": 73,
      "name": "Dockerfile-First Workers: cozy.toml Support in python-gen-worker (No tool.cozy in pyproject.toml)",
      "description": "Align python-gen-worker with Cozy Hub issue #102 (Dockerfile-first workers).\n\nTenants should not need any Cozy-specific configuration in `pyproject.toml`. Instead, Dockerfile-first workers use a `cozy.toml` manifest (flat schema).\n\nVersioning/compat policy update:\n- `cozy.toml` includes a `gen_worker` version constraint (for the `gen-worker` runtime library).\n- Cozy Hub validates the built image satisfies that constraint at publish time.\n- python-gen-worker does not need to emit extra version/audit events for this purpose.\n\npython-gen-worker must be able to:\n- read `cozy.toml` (for discovery import target and model-id mapping)\n- run discovery based on manifest `main`\n- stop parsing `[tool.cozy.*]` from `pyproject.toml`\n\nRelated Cozy Hub spec:\n- `~/cozy/cozy-hub/docs/cozy-toml.md`\n",
      "tasks": [
        "[ ] Add cozy.toml manifest parser (v1)\n    - Define a small typed parser in python-gen-worker (tomllib)\n    - Support: schema_version, name, main, gen_worker constraint string, [host.requirements].cuda constraint string, [models] mapping\n    - Default path: `/cozy/cozy.toml`\n    - Optional override: env `COZY_MANIFEST_PATH` (dev/testing only)",
        "[ ] Update discovery to use cozy.toml\n    - If `COZY_MANIFEST_PATH` (or `/cozy/cozy.toml`) exists:\n      - use `main` as the import target(s) for discovery\n      - use `[models]` mapping as the release model keyspace (replaces `[tool.cozy.models]`)\n    - Require a manifest (no environment-variable-based module selection)\n    - Remove all reads of `[tool.cozy.*]` from `pyproject.toml` (no Cozy config in pyproject)",
        "[ ] Update runtime model-key mapping contract\n    - Ensure payload short-key selection (ModelRefSource.PAYLOAD) uses the manifest `[models]` mapping\n    - Keep the \"payload must be a short key\" safety rule",
        "[ ] Remove/relax build-time manifest generation coupling\n    - Ensure the worker can run without `/app/.cozy/manifest.json` when Cozy Hub/orchestrator already provides function schemas\n    - Keep backward compatibility in dev mode only (optional)",
        "[ ] Optional: runtime validation (dev)\n    - If `cozy.toml` is present, optionally validate the local installed `gen-worker` version satisfies `gen_worker` constraint and log a clear error if not (dev-only).\n    - Production enforcement should be done by Cozy Hub at publish time.",
        "[ ] Docs\n    - Update `README.md` and example guidance:\n      - Cozy config lives in `cozy.toml`, not `pyproject.toml`\n      - show minimal `cozy.toml` and how the worker finds it\n      - document `gen_worker` constraint semantics (Cozy Hub validates at publish time)",
        "[ ] Tests\n    - Unit tests: parse cozy.toml, missing/invalid schema_version, invalid cuda constraint string\n    - Unit tests: discovery uses cozy.toml main + models mapping\n    - Unit tests: payload short-key mapping uses cozy.toml [models]"
      ],
      "completed": false
    },
    {
      "id": 74,
      "name": "Endpoint-Constrained DType Selection (FP16/BF16/FP8) Across Cozy Hub + Orchestrator + Worker",
      "description": "Problem: gen-orchestrator cannot arbitrarily switch a repo's dtype/quantization (e.g. fp16 -> fp8) for an endpoint and expect tenant code to work. Some endpoints are written for fp16/bf16 pipelines, while fp8 requires different loading/runtime code.\n\nGoal: each endpoint (via its worker project manifest) must declare:\n- which repos/components it can use (already via `[tool.cozy.models]` + `ModelRef(FIXED|PAYLOAD, ...)`)\n- which weight dtypes are acceptable for each model key (e.g. [\"fp16\",\"bf16\"], but NOT fp8 unless the endpoint explicitly opts in)\n\nOrchestrator must:\n- compute required repo refs for a request (static + payload-driven)\n- intersect client \"variant preferences\" (flashpack vs safetensors) with endpoint-allowed dtypes\n- resolve to a concrete variant ref (snapshot digest) that matches those constraints\n\nNotes:\n- Packaging differences (flashpack vs safetensors) should be transparent to tenant code; the worker loader handles it.\n- DType/quantization differences (fp16/bf16/fp8) are NOT transparent and must be constrained by the endpoint.\n",
      "tasks": [
        "[ ] python-gen-worker: extend `[tool.cozy.models]` to express allowed dtypes per key\n    - Proposed TOML (example):\n      - `sdxl = { ref = \"cozy:stabilityai/sdxl:latest\", dtypes = [\"fp16\",\"bf16\"] }`\n      - `flux_fp8 = { ref = \"cozy:black-forest-labs/flux-2-klein-4b:latest\", dtypes = [\"fp8\"] }` (only if endpoint code supports fp8)\n    - Support `#component` in `ref` values (already supported by ref strings)\n    - Back-compat strategy (if needed): if value is a string, treat it as `{ref=<string>, dtypes=[\"fp16\",\"bf16\"]}` to avoid accidental fp8 selection\n    - Document the schema in README/docs",
        "[ ] python-gen-worker: discovery/manifest emits dtype constraints\n    - Update `discover.py` to parse the new `[tool.cozy.models]` shape\n    - Keep a clear manifest contract for schedulers:\n      - `models_by_key[key] = { ref: \"cozy:owner/repo:tag\", dtypes: [..] }`\n      - Continue emitting `payload_repo_selectors` and `required_models` (keys)\n    - Add tests covering string vs table forms and dtype defaults",
        "[ ] gen-orchestrator: treat model keys as (repo ref + allowed dtypes)\n    - Persist the manifest's per-key dtype allowlist on the deployment/release record\n    - When computing required repos for a request, also compute required dtype constraints per injection key\n    - Reject requests that ask for a dtype outside the endpoint-allowed set (safe validation error)\n    - When choosing a variant, filter candidates to those whose dtype/quant is allowed for that key",
        "[ ] gen-orchestrator: client per-request variant preferences become bounded overrides\n    - Define a reserved request metadata field (e.g. `cozy_meta.variant_prefs`) that may request:\n      - `packaging`: flashpack|safetensors\n      - `dtype`: fp16|bf16|fp8 (optional)\n    - Enforce: requested dtype must be in endpoint allowed dtypes\n    - Allow policy-based selection (e.g. some users get bf16, others fp16) but always within the endpoint constraint",
        "[ ] cozy-hub: expose dtype/quantization metadata for variants in resolve APIs\n    - Ensure resolve_artifact responses include dtype/quant for each returned variant\n    - Ensure variant labels/fields align with orchestrator filters: fp16/bf16/fp8\n    - (Optional) add Cozy Hub-side guardrails: allow registering variants with declared dtype + required runtime libs",
        "[ ] python-gen-worker: runtime enforcement and cache keys\n    - Ensure pipeline caching keys include variant ref (snapshot digest) AND dtype so fp16/bf16/fp8 don't collide\n    - Ensure the loader uses a torch_dtype consistent with the selected variant (esp. bf16 vs fp16 on CUDA)\n    - Fail fast if asked to load a variant dtype the endpoint did not declare (defense-in-depth; orchestrator should prevent this)",
        "[ ] End-to-end tests\n    - One endpoint declares dtypes=[fp16,bf16] and a repo; orchestrator must never resolve fp8 for it\n    - Another endpoint declares dtypes=[fp8] and uses fp8-specific tenant code; orchestrator must resolve fp8 and worker must load it\n    - Packaging preference (flashpack vs safetensors) can vary without changing tenant code"
      ],
      "completed": false
    }
  ]
}
