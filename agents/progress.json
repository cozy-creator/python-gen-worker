{
  "issues": [
    {
      "name": "Signature-based dependency injection (typing.Annotated + ModelRef)",
      "description": "Adopt the new tenant function contract where models/processors/pipelines are injected via `typing.Annotated[..., ModelRef(...)]` instead of decorator flags like expects_pipeline_arg. The worker owns downloads + VRAM lifecycle; tenant code receives ready-to-use objects. Keep `@worker_function` minimal (marker + requires_gpu) and rely on signature inspection for injection and validation.",
      "tasks": [
        "[ ] Add `gen_worker.injection` module defining:\n    - `ModelRefSource` enum (at least: DEPLOYMENT, PAYLOAD_LABEL)\n    - `ModelRef` annotation helper carrying (source, default_model_id, label_key?)\n    - Strong typing via `typing.Annotated` metadata and `typing.get_type_hints(..., include_extras=True)`.",
        "[ ] Add `ModelArtifacts` injection type for non-standard runtimes:\n    - Injects local artifact paths (a directory + named files map) for a resolved model ref\n    - Used when tenant code imports a custom runtime (e.g. krea-ai/realtime-video) and loads weights itself\n    - Source of truth for artifact keys is deployment config (not inferred from repo contents).",
        "[ ] Define injection resolution rules (document + implement):\n    - DEPLOYMENT: inject the deployment-configured model_id\n    - PAYLOAD_LABEL: payload chooses a model_id from a deployment allowlist via a reserved label\n    - Reject any model_id not allowlisted for the deployment.",
        "[ ] Implement injection in the worker call wrapper:\n    - Inspect function signature including Annotated metadata\n    - Build injected args before invoking tenant code\n    - Keep payload decoding (msgspec) + Asset materialization as today.",
        "[ ] Implement a minimal injection catalog (torch backend first):\n    - Inject `AutoModelForCausalLM`-style models and `AutoProcessor`/tokenizers\n    - Inject diffusers pipelines when the annotation requests a pipeline type\n    - Inject `ModelArtifacts` when the annotation requests artifact paths instead of a ready runtime object\n    - Ensure injection is cheap at invocation time (reuse cached objects; no from_pretrained in tenant code).",
        "[ ] Support tenant-provided loader hooks for custom runtime handles:\n    - Allow tenant projects to register a loader callable that builds a custom runtime handle (e.g. `KreaRuntime`) from `ModelArtifacts`\n    - The worker/model-manager should run the loader once per resolved model ref (load into VRAM), cache the returned object, and inject it into functions/websocket handlers\n    - Define lifecycle: cache keys, refcounts/leases for websocket sessions, and eviction on memory pressure or idle timeout.",
        "[ ] Tighten `@worker_function` usage:\n    - Keep decorator only as a marker + `requires_gpu` (and maybe max_concurrency)\n    - Ignore/remove expects_pipeline_arg / expects_model_bundle_arg in the new contract.",
        "[ ] Schema reporting: include injection metadata per function (requires orchestrator proto/schema changes) so deployments can be registered without out-of-band docs.",
        "[ ] Reserved payload fields for model selection:\n    - Decide a single reserved field name (e.g. `model_id`)\n    - Ensure it is not part of the msgspec payload struct and is only used for PAYLOAD_LABEL resolution.",
        "[ ] Tests:\n    - Annotated model + processor injection works\n    - ModelArtifacts injection returns stable local paths and named keys\n    - Loader hook is used for custom runtime types and returns cached VRAM-resident handles\n    - PAYLOAD_LABEL rejects non-allowlisted ids\n    - No legacy decorator flags are required for injection."
      ],
      "completed": false
    },
    {
      "name": "Strict typed tenant contract (msgspec input/output inferred from signature)",
      "description": "Enforce that tenant functions use strongly-typed `msgspec.Struct` for inputs and outputs, inferred from the function signature (no dict payloads, no explicit input_model/output_model args). This makes function invocation safer and enables orchestrator-side JSON validation against the exact schema the function expects.",
      "tasks": [
        "[ ] Define the canonical function signature rules (and enforce at discovery time):\n    - Must accept `ctx: ActionContext` as the first arg\n    - Must accept exactly one payload arg, and its type must be a `msgspec.Struct` subclass\n    - May accept additional injected args via `typing.Annotated[..., ModelRef(...)]`\n    - Reject untyped parameters and reject `dict`/`Any` payloads.",
        "[ ] Implement signature inspection utilities using `typing.get_type_hints(..., include_extras=True)` and `inspect.signature`:\n    - Identify payload parameter and payload struct type\n    - Identify injected parameters (Annotated + ModelRef metadata)\n    - Identify output mode from return annotation: `msgspec.Struct` or `Iterator[msgspec.Struct]` (incremental output).",
        "[ ] Update function discovery to fail fast with clear errors when a function violates the contract (include function name/module and rule violated).",
        "[ ] Update invocation wrapper to decode payload strictly as the inferred `msgspec.Struct` type (unknown fields rejected; defaults applied by msgspec).",
        "[ ] Update output handling:\n    - Non-incremental: require returned value is instance of the annotated output `msgspec.Struct`\n    - Incremental: require iterator yields instances of the annotated delta `msgspec.Struct`.\n    - Convert outputs to builtins (`msgspec.to_builtins`) before msgpack encoding for Go compatibility (keep this behavior).",
        "[ ] Enforce that dict-based payload handlers are not supported (fail discovery with a clear error).",
        "[ ] Tests:\n    - Reject dict payloads\n    - Reject missing ctx\n    - Reject missing return annotations\n    - Accept typed functions with injected params + msgspec payload\n    - Ensure schema hashes/identifiers are stable (if used downstream)."
      ],
      "completed": false
    },
    {
      "name": "Incremental output: generator functions + typed output events",
      "description": "Add first-class support for incremental output from tenant functions (e.g. token-by-token output). The worker should support functions that yield typed deltas and/or explicitly emit typed output events, and forward those incrementals to the scheduler as ordered job events without requiring tenants to manage storage/VRAM. (\"Streaming\" over WebSockets is a separate feature.)",
      "tasks": [
        "[ ] Infer incremental output from the function return annotation (`Iterator[DeltaStruct]` / `Iterable[DeltaStruct]`) rather than adding decorator flags.",
        "[ ] Extend function discovery to support two output modes:\n    - non-incremental: return type is `msgspec.Struct`\n    - incremental: return type is `Iterator[msgspec.Struct]` / `Iterable[msgspec.Struct]` (delta type) and/or `Generator[msgspec.Struct, None, FinalStruct?]` (future: separate final type).",
        "[ ] Define a minimal, stable event taxonomy for incremental output emitted by the worker:\n    - `output.delta` (payload is a JSON object derived from the yielded msgspec struct)\n    - `output.completed` (optional; emitted when the iterator finishes)\n    - `output.error` (emitted on exception before the final RunResult)\n    Keep existing `job.progress` / `job.log` events unchanged.",
        "[ ] Implement iterator execution path in the worker wrapper:\n    - If function returns an iterator, iterate and emit `output.delta` for each item\n    - Apply basic rate limiting/coalescing knobs (env-configurable): max events/sec, max payload bytes per event\n    - Respect cancellation: stop iterating promptly when InterruptTaskCommand is received or ctx.is_canceled() becomes true.",
        "[ ] Ensure emitted deltas are strictly JSON-serializable (use `msgspec.to_builtins` then JSON dump) and enforce a small per-delta size limit to prevent DB bloat.",
        "[ ] Preserve existing RunResult semantics:\n    - For incremental-output functions, RunResult `output_payload` should contain a small final summary object (or be empty) while incremental output is delivered via events.\n    - For non-incremental functions, keep current behavior.",
        "[ ] Extend schema reporting to include incremental-output metadata (requires proto changes in scheduler message types) so orchestrator can advertise/validate whether a function has incremental output and what its delta schema is.",
        "[ ] Add unit tests:\n    - iterator yields N deltas -> emits N ordered `WorkerEvent` messages\n    - iterator cancellation -> stops early and emits canceled result\n    - oversize delta -> fail with validation error / drop with structured `output.error` (decide behavior and test it).",
        "[ ] Add an example incremental-output function in /worker-example-functions (LLM token delta stub) that yields deltas and can be observed via `/v1/jobs/<id>/events`."
      ],
      "completed": false
    },
    {
      "name": "WebSocket realtime functions (worker-side runtime)",
      "description": "Support true WebSocket realtime endpoints (bidirectional) without exposing workers publicly. Tenant code registers an async handler (e.g. `@worker_websocket`) and uses a gen-worker-owned socket interface. The worker talks to gen-orchestrator over a bidirectional internal transport stream; gen-orchestrator http-api proxies to/from the browser WebSocket and handles auth + rate limiting.",
      "tasks": [
        "[ ] Define a worker-owned `RealtimeSocket` interface (no FastAPI dependency):\n    - `accept()` / `close(code?, reason?)`\n    - `receive_bytes()` / `send_bytes()`\n    - `send_json()` convenience (optional)\n    - Backpressure semantics: `send_*` is awaitable; buffers are bounded.",
        "[ ] Add `@worker_websocket` decorator (marker only) and discovery:\n    - Identify websocket handlers separately from job functions\n    - Enforce signature: `(ctx: ActionContext, ws: RealtimeSocket, ...injected...) -> Awaitable[None]`.",
        "[ ] Add internal realtime session loop over worker transport:\n    - Extend/define a worker RPC for realtime: `OpenRealtimeSession(init) <-> stream Frame`\n    - Map inbound frames to `RealtimeSocket.receive_*` and outbound frames from `RealtimeSocket.send_*`.\n    - Support binary frames as the primary payload; allow tiny JSON control messages (ready/status).",
        "[ ] Injection support for realtime handlers:\n    - Allow websocket handlers to receive injected deps via `typing.Annotated[..., ModelRef(...)]`\n    - Resolve injection once per session (not per frame) and cache for session lifetime.",
        "[ ] Cancellation + cleanup:\n    - If the orchestrator closes/cancels the session, propagate cancellation to tenant handler and close socket\n    - Ensure model manager releases/evicts resources according to policy after session end.",
        "[ ] Safety limits (defense-in-depth):\n    - Enforce `WORKER_MAX_WS_FRAME_BYTES` and drop/close on oversize frames\n    - Enforce optional idle timeout from orchestrator (no frames for N seconds).",
        "[ ] Tests:\n    - Unit test socket adapter mapping (transport frames <-> handler calls)\n    - Integration smoke: echo handler that sends a ready JSON message then echoes binary frames."
      ],
      "completed": false
    },
    {
      "name": "Alternative backends: ONNX Runtime + TensorRT runtime handles",
      "description": "Add first-class support for non-torch execution backends by injecting backend-specific runtime handles into tenant functions via `typing.Annotated[..., ModelRef(...)]`. Strict artifact boundaries: ONNX uses `.onnx`(+external data) artifacts, TensorRT uses prebuilt `.engine` artifacts with explicit compatibility metadata. No exporting/building on worker boot.",
      "tasks": [
        "[ ] Packaging extras:\n    - Add `gen-worker[onnxruntime]` (onnxruntime-gpu + minimum helpers)\n    - Add `gen-worker[tensorrt]` (tensorrt python bindings + minimum helpers)\n    - Ensure core package stays lightweight; backend deps are optional extras.",
        "[ ] Backend runtime handle interfaces (worker-owned):\n    - Define minimal protocols/types for injected handles (e.g. `OrtPipelineLike` / `OrtRuntime`, `TrtRuntime`)\n    - Keep tenant-visible types stable; internal implementation can vary per image/version.",
        "[ ] Model manager implementations:\n    - ONNX: download/caches ONNX graphs, instantiate and cache `onnxruntime.InferenceSession` (GPU provider), optional warmup\n    - TensorRT: download/caches engine blobs, deserialize engines, allocate buffers, expose a small runner object\n    - Enforce: no export to ONNX and no engine builds at worker startup/invocation.",
        "[ ] Compatibility gating (TensorRT):\n    - Require artifact metadata (at least cuda_version, tensorrt_version, sm) in the invocation envelope\n    - Fail fast with a safe error if the runtime/host is incompatible with the selected engine artifact.",
        "[ ] Injection catalog extension:\n    - Allow injection of ONNX runtime handles when parameter type matches (e.g. `ORTStableDiffusionPipeline` or Cozy wrapper)\n    - Allow injection of TensorRT runtime handles (Cozy wrapper types)\n    - Ensure injection is one-time per process/session and reused across invocations where safe.",
        "[ ] Tests:\n    - Unit test injection selection for a fake ONNX handle and fake TensorRT handle\n    - Unit test compatibility mismatch produces a structured safe error\n    - (Optional) e2e smoke in CPU-only mode with onnxruntime CPU provider stub."
      ],
      "completed": false
    },
    {
      "name": "Support orchestrator queue/long-poll API (bytes + multipart inputs)",
      "description": "Ensure python-worker cleanly supports the orchestratorâ€™s simplified API surface: queue (job id) + long-poll (Prefer: wait), raw-bytes primary output for long-poll, and multipart-uploaded inputs proxied through cozy-hub. Worker should never see base64/data-URIs or multipart form parts; it should only see msgpack inputs with resolved Asset refs/URLs.",
      "tasks": [
        "[x] Confirm function discovery reports msgspec JSON schemas that accept file inputs as `Asset` (never `data:` URIs, never `form_file`).",
        "[x] Ensure input materialization supports both cozy-hub refs and external URLs with strict size caps (`WORKER_MAX_INPUT_FILE_BYTES`) and SSRF protections for URL downloads.",
        "[x] Ensure output contract for file outputs is `Asset` (or list of `Asset`), stored under reserved prefixes (e.g. `runs/<run_id>/outputs/...`), so orchestrator can reliably pick a primary output.",
        "[x] Ensure `ctx.save_bytes/ctx.save_file` always persist to cozy-hub file API and return populated `Asset` metadata (ref/sha/size/mime) for downstream URL/bytes fetching by the orchestrator.",
        "[x] Add unit tests for asset materialization (external URL + cozy-hub ref) with size caps enforced (mock urllib).",
        "[x] Document that `output_format` only affects orchestrator HTTP responses; worker behavior is storage-first."
      ],
      "completed": true
    },
    {
      "name": "Expanded structured error taxonomy + sanitization",
      "description": "Expand beyond retryable/fatal into a richer, typed error taxonomy for tenant functions and ensure python-worker always returns a single structured error payload to the scheduler (with strict sanitization for client-facing messages).",
      "tasks": [
        "[x] Add tenant-facing error classes to gen_worker.errors: ValidationError, ResourceError, CanceledError (keep RetryableError/FatalError).",
        "[x] Define canonical error payload shape emitted by python-worker for all failures: {error_type, retryable, safe_message} (internal error string kept for logs/back-compat).",
        "[x] Implement exception->error mapping layer in python-worker runtime:\n    - ValidationError/ValueError -> error_type=validation, retryable=false\n    - RetryableError -> error_type=retryable, retryable=true\n    - FatalError -> error_type=fatal, retryable=false\n    - ResourceError (incl. torch OOM by name) -> error_type=resource, retryable=false\n    - CanceledError/interrupt -> error_type=canceled, retryable=false\n    - unknown exception -> error_type=internal, retryable=false",
        "[x] Implement sanitization policy for safe_message: strip obvious tokens (Bearer ...), URLs, and local filesystem paths; log detailed errors server-side with correlation to run_id.",
        "[x] Add tests coverage: mapping produces expected {error_type,retryable}; safe_message redacts tokens/urls/paths."
      ],
      "completed": true
    },
    {
      "name": "Worker leader discovery + failover",
      "description": "Add multi-seed scheduler discovery and automatic leader redirect handling for Raft deployments.",
      "tasks": [
        "[x] Add SCHEDULER_ADDRS env (comma-separated) alongside SCHEDULER_ADDR",
        "[x] Try seed addresses on startup until a connection succeeds",
        "[x] On stream failure, retry across the seed list with backoff",
        "[x] Parse FailedPrecondition not_leader:<addr> and reconnect immediately",
        "[x] Add minimal test or smoke coverage for redirect handling"
      ],
      "completed": true
    },
    {
      "name": "Worker runtime enhancements (outputs, progress, limits)",
      "description": "Improve worker ergonomics for serverless inference: direct output uploads, progress events, and concurrency caps.",
      "tasks": [
        "[x] Add direct output upload support to platform-managed file storage",
        "[x] Return output metadata (url/key/size/sha256) instead of raw bytes when uploaded",
        "[x] Deprecate/remove raw output byte streaming for large outputs (keep only small payloads)",
        "[x] Add ctx.emit() (progress/events) and forward to scheduler",
        "[x] Add per-worker/per-function concurrency limits and advertise to scheduler",
        "[x] Add basic validation for input/output payloads (msgpack + optional schema)",
        "[x] Add structured error taxonomy (retryable vs fatal)",
        "[x] Report richer resource info (GPU name, VRAM total/free, driver version)",
        "[x] Add heartbeat backoff + jitter on disconnect/reconnect",
        "[x] Add graceful shutdown to drain in-flight jobs",
        "[x] Enforce configurable max payload sizes (input/output)",
        "[x] Verify scheduler JWT on connect (asymmetric signature)",
        "[x] Fetch scheduler JWKS from configured URL and cache with TTL",
        "[x] Handle JWKS rotation (refresh on key ID miss)",
        "[x] Fail closed when JWT verification fails"
      ],
      "completed": true
    },
    {
      "name": "Example worker functions repo",
      "description": "Co-evolve /worker-example-functions with python-worker so gen-builder can deploy consistent tenant examples.",
      "tasks": [
        "[x] Decide on the example project layout (functions module/package, deps via pyproject.toml and/or uv.lock, TOML manifest via cozy.toml)",
        "[x] Create multiple example subfolders (minimal, image-gen, s3-upload, etc.) under /worker-example-functions",
        "[x] Ensure each example imports gen_worker and uses @worker_function metadata",
        "[x] Enforce dependency policy: no requirements.txt; require pyproject.toml and/or uv.lock (uv-first)",
        "[x] Add cozy.toml entries to examples (functions.modules, runtime.base_image, optional limits)",
        "[x] Align dependencies to python-worker SDK version and document how to deploy with gen-builder",
        "[x] Add README per example with inputs/outputs and required env vars"
      ],
      "completed": true
    },
    {
      "name": "Python worker SDK cleanup",
      "description": "Position python-worker as a pure pip package and move example projects into /worker-example-functions.",
      "tasks": [
        "[x] Remove or relocate python-worker/example-functions and image_gen_example",
        "[x] Update python-worker README to describe SDK usage and point to /worker-example-functions",
        "[x] Ensure packaging stays intact (pyproject.toml + src/gen_worker)",
        "[x] Add or update minimal docs for decorators, function signature, and dependency policy (pyproject.toml + uv.lock only, cozy.toml manifest)",
        "[x] Document the recommended contract for dynamic checkpoint selection (model family in metadata, model_ref provided at runtime)",
        "[x] Document the build contract: tenant deps in pyproject.toml/uv.lock, Cozy config in cozy.toml, gen-builder bakes into a worker image for gen-orchestrator",
        "[x] Verify the examples install gen-worker as a dependency and import cleanly"
      ],
      "completed": true
    },
    {
      "name": "JWT RSA import safety",
      "description": "Avoid import-time failures when PyJWT lacks RSA support; ensure JWKS verification is available when configured.",
      "tasks": [
        "[x] Guard RSAAlgorithm import and raise only when JWKS is actually used",
        "[x] Require PyJWT crypto extra to ensure RSAAlgorithm is available in standard installs",
        "[x] Reinstall and smoke test example imports to confirm no crash"
      ],
      "completed": true
    },
    {
      "name": "gen-worker core + torch add-on split",
      "description": "Separate lightweight orchestration SDK from torch-specific model memory management, with a clean interface between them.",
      "tasks": [
        "[x] Define core responsibilities: orchestrator comms/job loop, request/response handling, function discovery, decorators/metadata, ActionContext, errors, progress events, S3 uploads",
        "[x] Keep model downloading from Cozy hub in core (async downloader + retries + progress; no huggingface_hub dependency)",
        "[x] Core must integrate downloader -> local model path -> ModelManager.load/unload/get calls (abstract interface; no torch imports)",
        "[x] Define a ModelManager interface in core (load/get/unload/stats) with no torch imports",
        "[x] Move default_model_manager and torch-specific utilities behind an optional add-on (torch extra or separate module)",
        "[x] Remove torch/diffusers/transformers/accelerate/etc. from core dependencies; keep only grpc/protobuf/msgpack/jwt/psutil/boto3 plus aiohttp/backoff/tqdm for downloader/retry/progress",
        "[x] Add optional dependency group for torch runtime (torch, torchvision, torchaudio, safetensors, flashpack, numpy; keep xformers tenant-only)",
        "[x] Update worker to accept a ModelManager instance or plugin path (env) and run without torch when none provided",
        "[x] Document the split and install modes: gen-worker (core) vs gen-worker[torch] (runtime)",
        "[x] Audit imports to ensure torch-only code is isolated and not required for basic worker startup"
      ],
      "completed": true
    },
    {
      "name": "Standardize deployment config in pyproject.toml ([tool.cozy])",
      "description": "Remove the separate cozy.toml manifest and standardize all tenant deployment configuration under `pyproject.toml` in `[tool.cozy]` (uv-first). Keep docs and examples consistent across python-worker and worker-example-functions.",
      "tasks": [
        "[ ] Update docs:\n    - Update python-worker README and the e2e spec to use `[tool.cozy]` only\n    - Remove any mention of cozy.toml as a supported config path.",
        "[ ] Update worker-example-functions:\n    - Move any `cozy.toml` settings into `pyproject.toml` under `[tool.cozy]` for each example\n    - Delete `cozy.toml` files from examples (or fail CI if present).",
        "[ ] Update worker-side config parsing (if any exists):\n    - Ensure no code path attempts to load a separate cozy.toml file\n    - Treat missing `[tool.cozy]` as a hard error when running discovery/build tooling.",
        "[ ] Add a small validation helper (optional):\n    - A `gen_worker.validate_project()` utility that checks for `[tool.cozy]`, `uv.lock` presence (if required), and rejects requirements.txt/cozy.toml.",
        "[ ] Tests:\n    - Example projects still import and pass mypy\n    - Any lingering cozy.toml usage is rejected by the validation helper (if added)."
      ],
      "completed": false
    }
  ]
}
