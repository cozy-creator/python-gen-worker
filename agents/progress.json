{
  "issues": [
    {
      "id": 71,
      "name": "Dev HTTP Runner: Invoke Any Endpoint in a Worker Image via curl (Local Outputs)",
      "description": "Add a dev-only HTTP mode to python-gen-worker so a built worker image can be run locally and invoked with one-off HTTP requests (e.g. via curl), without standing up gen-orchestrator.\n\nGoals:\n- Start the container, mount a local output directory, then invoke any discovered endpoint/function with arbitrary JSON input.\n- All output files must be written to a mounted local directory (no Cozy Hub file API required).\n- Model weights should load on-demand during the first request (works today), but the dev server should also support explicit prefetch/warmup to avoid timeouts.\n\nNon-goals (v1):\n- Replacing the production scheduler protocol.\n- Matching every orchestrator behavior (autoscaling, queueing, JWT auth, etc.).\n\nKey design point:\n- In prod, the orchestrator instructs the worker via gRPC and provides per-run file capability tokens. In dev HTTP mode, we run the same function invocation engine in-process and swap the file backend to local-disk writes.\n",
      "tasks": [
        "[x] Define dev HTTP API contract\n    - Implemented:\n      - `POST /v1/run/{function_name}`\n      - `GET /v1/status`\n      - `GET /v1/models/status`\n      - `POST /v1/models/prefetch`\n      - `POST /v1/models/load`\n      - `POST /v1/models/unload`\n      - `POST /v1/warmup/{function_name}` (alias of run for init/warmup)",
        "[x] Implement local file backend for ActionContext\n    - `ActionContext(local_output_dir=...)` makes `ctx.save_*` write under that dir\n    - Preserves `runs/{run_id}/outputs/...` ref rules\n    - Returns `Asset(local_path=...)` + size_bytes + sha256 without HTTP",
        "[x] Implement dev HTTP server entrypoint\n    - `python -m gen_worker.testing.http_runner --listen ... --outputs ...`\n    - Loads user modules from baked `/app/.cozy/manifest.json` (configurable via `--manifest`)\n    - Reuses existing msgspec decoding + injection + downloader + pipeline loader\n    - Incremental functions: emits worker events in response (collected list; no SSE in v1)",
        "[x] Implement model prefetch/load/unload/warmup behavior\n    - Prefetch downloads into `WORKER_MODEL_CACHE_DIR` and marks models cached-on-disk\n    - load/unload reuse the existing worker load/unload handlers and report their results\n    - warmup executes the endpoint once (best-effort)",
        "[x] Docs + examples\n    - Documented a canonical local workflow in `README.md`",
        "[x] Tests\n    - Added unit test for `ActionContext(local_output_dir=...)` local save backend\n    - Added minimal HTTP runner test that invokes an endpoint and asserts file written under outputs dir"
      ],
      "completed": true
    },
    {
      "id": 72,
      "name": "Payload Chooses Repo By Short Key (pyproject.toml) + Manifest Metadata for Orchestrator Routing",
      "description": "Intended contract: a client payload can select a repo by a short string (e.g. `\"model\": \"sd15\"`) and that short string maps to a canonical Cozy repo ref declared ahead of time in `pyproject.toml` under `[tool.cozy.models]` (short-key -> `cozy:owner/repo[:tag][#component]`).\n\nToday, python-gen-worker supports signature-driven injection from payload via `Annotated[..., ModelRef(ModelRefSource.PAYLOAD, \"field_name\")]`, and resolves the chosen short key through the release-provided short-key mapping (legacy field name: `model_id_by_key`).\n\nWhat is missing for end-to-end cache-aware routing is making this contract explicit and exportable:\n- PAYLOAD values must be *keys*, not arbitrary refs\n- The orchestrator must know which payload fields select repos so it can compute required repo refs at submit-time",
      "tasks": [
        "[x] Enforce short-key semantics for ModelRef(PAYLOAD, ...)\n    - Require the payload value is a key present in the release short-key mapping (from `[tool.cozy.models]`)\n    - Unknown key: fail with a clear safe validation error (bounded list of allowed keys)\n    - Keep ModelRef(RELEASE, ...) behavior unchanged",
        "[x] Manifest metadata for orchestrator routing\n    - In `discover.py`, include which payload fields are repo selectors for each function\n    - Example: `payload_repo_selectors: [{\"field\":\"model\",\"kind\":\"short_key\"}]`\n    - Keep `injection_json` as the source of truth; this is a stable convenience for schedulers",
        "[x] Clarify manifest semantics\n    - `[tool.cozy.models]` defines the complete allowlisted keyspace and the repo ref each key maps to\n    - Ensure components (`#unet`, etc.) are representable in the ref value",
        "[x] Docs\n    - Show the pattern end-to-end: `[tool.cozy.models]` + payload short-key + `ModelRef(PAYLOAD, ...)`\n    - Document that direct repo refs in payload are not supported unless explicitly opted-in (future)",
        "[x] Tests\n    - Unit tests for PAYLOAD model selection: unknown key, known key, invalid types\n    - Discover-manifest test: `payload_repo_selectors` emitted when PAYLOAD injections exist"
      ],
      "completed": false
    },
    {
      "id": 73,
      "name": "Dockerfile-First Workers: cozy.toml Support in python-gen-worker (No tool.cozy in pyproject.toml)",
      "description": "Align python-gen-worker with Cozy Hub issue #102 (Dockerfile-first workers).\n\nTenants should not need any Cozy-specific configuration in `pyproject.toml`. Instead, Dockerfile-first workers use a `cozy.toml` manifest (flat schema).\n\nVersioning/compat policy update:\n- `cozy.toml` includes a `gen_worker` version constraint (for the `gen-worker` runtime library).\n- Cozy Hub validates the built image satisfies that constraint at publish time.\n- python-gen-worker does not need to emit extra version/audit events for this purpose.\n\npython-gen-worker must be able to:\n- read `cozy.toml` (for discovery import target and model-id mapping)\n- run discovery based on manifest `main`\n- stop parsing `[tool.cozy.*]` from `pyproject.toml`\n\nRelated Cozy Hub spec:\n- `~/cozy/cozy-hub/docs/cozy-toml.md`\n",
      "tasks": [
        "[x] Add cozy.toml manifest parser (v1)\n    - Implemented `src/gen_worker/cozy_toml.py` (tomllib)\n    - Supports: schema_version, name, main, gen_worker, [host.requirements].cuda, [models] mapping\n    - Supports optional per-endpoint model mapping: `[endpoints.<endpoint_name>.models]`\n    - Load path: `./cozy.toml` by default; env override `COZY_MANIFEST_PATH` (dev/testing only)",
        "[x] Update discovery to use cozy.toml\n    - Discovery requires cozy.toml (no Cozy config in pyproject.toml)\n    - Uses `main` as the import target for discovery (imports main, then inspects newly-imported modules)\n    - Uses `[models]` mapping (and optional `[endpoints.<endpoint_name>.models]`) as the model keyspace\n    - Emits per-function model mapping in the baked manifest under `models_by_function`",
        "[x] Update runtime model-key mapping contract\n    - Payload short-key selection (ModelRefSource.PAYLOAD) uses the baked `manifest.json` per-function mapping (`models_by_function`)\n    - Keeps the \"payload must be a short key\" safety rule\n    - Allows endpoint-specific model keyspaces so endpoints in the same release can support different models/dtypes",
        "[x] Manifest requirement\n    - Worker ENTRYPOINT requires `/app/.cozy/manifest.json` in the image (Dockerfile-first contract).\n    - The worker does not need cozy.toml at runtime; cozy.toml is build-time input only.",
        "[x] Optional: runtime validation (dev)\n    - Implemented dev-only check in `src/gen_worker/entrypoint.py`: if `COZY_MANIFEST_PATH` points at cozy.toml, validate installed gen-worker version satisfies `gen_worker` constraint (exit 2 on mismatch)\n    - Added unit tests for constraint evaluation in `tests/test_cozy_toml.py`",
        "[x] Docs\n    - Updated `README.md` to document Dockerfile-first contract + cozy.toml `[models]`\n    - Documented dtype table form and default dtype behavior",
        "[x] Tests\n    - Added cozy.toml parser tests: `tests/test_cozy_toml.py`\n    - Updated discovery model tests for dtype table form: `tests/test_discover_models.py`\n    - Added worker payload short-key mapping test: `tests/test_worker_model_keyspace.py`"
      ],
      "completed": false
    },
    {
      "id": 74,
      "name": "Endpoint-Constrained DType Selection (FP16/BF16/FP8) Across Cozy Hub + Orchestrator + Worker",
      "description": "Problem: gen-orchestrator cannot arbitrarily switch a repo's dtype/quantization (e.g. fp16 -> fp8) for an endpoint and expect tenant code to work. Some endpoints are written for fp16/bf16 pipelines, while fp8 requires different loading/runtime code.\n\nGoal: each endpoint (via its worker project manifest) must declare:\n- which repos/components it can use (already via `cozy.toml [models]` + `ModelRef(FIXED|PAYLOAD, ...)`)\n- which weight dtypes are acceptable for each model key (e.g. [\"fp16\",\"bf16\"], but NOT fp8 unless the endpoint explicitly opts in)\n\nOrchestrator must:\n- compute required repo refs for a request (static + payload-driven)\n- intersect client \"variant preferences\" (flashpack vs safetensors) with endpoint-allowed dtypes\n- resolve to a concrete variant ref (snapshot digest) that matches those constraints\n\nNotes:\n- Packaging differences (flashpack vs safetensors) should be transparent to tenant code; the worker loader handles it.\n- DType/quantization differences (fp16/bf16/fp8) are NOT transparent and must be constrained by the endpoint.\n",
      "tasks": [
        "[x] python-gen-worker: extend `cozy.toml [models]` to express allowed dtypes per key\n    - Supported TOML:\n      - `sdxl = { ref = \"hf:stabilityai/stable-diffusion-xl-base-1.0\", dtypes = [\"fp16\",\"bf16\"] }`\n      - `flux_fp8 = { ref = \"hf:black-forest-labs/FLUX.2-klein-4B\", dtypes = [\"fp8\"] }`\n    - Back-compat: if value is a string, treat it as `{ref=<string>, dtypes=[\"fp16\",\"bf16\"]}`\n    - Implemented in `src/gen_worker/cozy_toml.py`",
        "[x] python-gen-worker: discovery/manifest emits dtype constraints\n    - `python -m gen_worker.discover` emits per-function dtype constraints under `models_by_function[function_name][model_key] = {ref,dtypes}`\n    - Supports endpoint-specific mapping via `[endpoints.<endpoint_name>.models]`\n    - Tests cover string vs table forms and dtype defaults",
        "[x] gen-orchestrator: treat model keys as (repo ref + allowed dtypes)\n    - Persisted model-key dtype allowlists on the deployment projection (`allowed_dtypes_by_key`)\n    - Submit-time required repo computation now also produces per-repo dtype constraints (static + payload-selected)\n    - Rejects per-request dtype overrides outside the endpoint allowlist (safe validation error)\n    - Variant resolution filters Cozy Hub quantization preferences per repo ref\n    - Safety default: scheduler no longer includes fp8 in the global default quantization preference list",
        "[x] gen-orchestrator: client per-request variant preferences become bounded overrides\n    - Reused existing `VariantPreferences` (packaging/layout/quant) as the per-request metadata channel\n    - Enforced that `quant` stays within the endpoint-allowed dtypes (no fp8 unless endpoint allows it)",
        "[x] cozy-hub: expose dtype/quantization metadata for variants in resolve APIs\n    - `resolve_artifact` / `resolve_variant` responses include `file_type`, `file_layout`, and `quantization` for the chosen variant",
        "[ ] python-gen-worker: runtime enforcement and cache keys\n    - Ensure pipeline caching keys include variant ref (snapshot digest) AND dtype so fp16/bf16/fp8 don't collide\n    - Ensure the loader uses a torch_dtype consistent with the selected variant (esp. bf16 vs fp16 on CUDA)\n    - Fail fast if asked to load a variant dtype the endpoint did not declare (defense-in-depth; orchestrator should prevent this)",
        "[ ] End-to-end tests\n    - One endpoint declares dtypes=[fp16,bf16] and a repo; orchestrator must never resolve fp8 for it\n    - Another endpoint declares dtypes=[fp8] and uses fp8-specific tenant code; orchestrator must resolve fp8 and worker must load it\n    - Packaging preference (flashpack vs safetensors) can vary without changing tenant code"
      ],
      "completed": false
    },
    {
      "id": 75,
      "name": "Model Downloads: Fallback To Cozy Hub Public Model Request When URLs Are Missing",
      "description": "Goal: when python-gen-worker is asked to download a model (via dev HTTP API or via the scheduler gRPC path) and it does NOT have presigned URLs for that model (no orchestrator-provided `resolved_cozy_models_by_id` entry), it should fall back to Cozy Hub's public model request endpoint and then download from the returned signed URLs.\n\nWhy:\n- This enables a simple local dev flow:\n  1) run a worker image locally\n  2) hit its dev HTTP API and ask for `sd15` (or `hf:runwayml/stable-diffusion-v1-5@main`)\n  3) the worker requests the public model from Cozy Hub and downloads it itself\n\nSecurity posture:\n- This is intended as a *dev/local convenience* and as a fallback for *public* models.\n- In production, we still prefer orchestrator-resolved presigned URLs as the normal/secure path.\n- Cozy Hub's public endpoint allows anonymous resolution only when the model is already mirrored; ingest-if-missing requires authentication.\n\nCozy Hub API:\n- `POST /api/v1/public/models/request`\n",
      "tasks": [
        "[x] Add Cozy Hub v2 client support for the public model request endpoint\n    - In `src/gen_worker/cozy_hub_v2.py`, add `request_public_model(model_ref, variant_label, include_urls=True)`\n    - Handle response codes:\n      - 200: parse `{owner, repo, tag, variant_label, snapshot_digest, snapshot_manifest.files[]}`\n      - 202: parse `{ingest_job_id}` (pending)\n      - 403: surface a clear error (model not mirrored and caller not authenticated)\n      - 409: surface `CozyHubNoCompatibleArtifactError` (no compatible variant)\n    - Keep types small and compatible with `CozySnapshotV2Downloader` (files list with {path,size_bytes,blake3,url})",
        "[x] Extend downloader to use public request when URLs are missing\n    - In `src/gen_worker/model_ref_downloader.py`:\n      - if a `cozy:` ref has no orchestrator-resolved entry and API resolve is allowed, prefer `public/models/request` over `resolve_artifact`\n      - if an `hf:` ref is used and `COZY_HUB_URL` is configured (and a new flag is enabled), prefer Cozy Hub public request (downloads from CAS) over huggingface_hub direct downloads\n    - Ensure this is gated by a new explicit flag (default false):\n      - `WORKER_ALLOW_COZY_HUB_PUBLIC_MODEL_REQUEST=1`\n    - Keep existing orchestrator-resolved behavior as the priority path",
        "[x] Pending/async ingest support (202 polling)\n    - Add a bounded polling loop when Cozy Hub returns 202:\n      - env: `WORKER_PUBLIC_MODEL_REQUEST_WAIT_TIMEOUT_S` (default 0 in prod; default non-zero in dev http-runner)\n      - exponential backoff (e.g. 0.5s -> 10s) with jitter\n      - stop with a clear error including `ingest_job_id` if timeout reached\n    - `GET /v1/models/load` and `POST /v1/models/prefetch` surface the pending state clearly when not waiting",
        "[x] Variant selection bridging\n    - Map the worker's requested model variant label (e.g. `safetensors-bf16`, `flashpack-bf16`, etc.) into the public request payload\n    - Ensure the returned `variant_label` is used for cache keys (defense against mismatches)",
        "[x] Update docs\n    - Update `README.md` dev HTTP runner docs:\n      - set `COZY_HUB_URL`\n      - optionally set `COZY_HUB_TOKEN` for ingest-if-missing\n      - set `WORKER_ALLOW_COZY_HUB_PUBLIC_MODEL_REQUEST=1`\n      - show `curl` example to prefetch/load sd1.5 using an `hf:` ref",
        "[x] Tests\n    - Unit tests for the new Cozy Hub client method using the existing test HTTP server harness:\n      - 200-ready response returns expected files + digest\n      - 202 pending is raised as `CozyHubPublicModelPendingError`\n    - ModelRefDownloader tests:\n      - hf refs prefer Cozy Hub public request when the flag is enabled\n      - 202 pending then 200 ready works via bounded polling"
      ],
      "completed": true
    },
    {
      "id": 76,
      "name": "Worker Stuck/Error Visibility: Startup, Runtime, and Scheduler Surfacing",
      "description": "Problem: workers can appear \"running\" at the pod level but never become usable (never register, block during startup/model load, or crash before signaling readiness). This currently looks like \"waiting for worker connection\" and can be hard to diagnose quickly.\n\nGoal: make stuck/error states explicit and actionable instead of silent. Operators should always be able to answer:\n- Did the worker start?\n- Which startup phase is it in?\n- Did it crash, and why?\n- Is it blocked on model download/load/inference?\n- Did scheduler/orchestrator detect and surface that state?\n\nThis issue includes python-gen-worker reporting plus orchestrator-facing signals/contract updates where needed.\n",
      "tasks": [
        "[x] Startup phase markers (structured logs/events)\n    - Emit structured phase transitions at boot: `boot`, `manifest_loaded`, `cache_preflight_ok|failed`, `scheduler_connecting`, `registered`, `ready`\n    - Include key debug fields: worker_id (if known), pod_id (if known), uid/gid, cache dirs, elapsed_ms since process start",
        "[x] Cache path preflight + actionable failure details\n    - Validate writeability of `WORKER_MODEL_CACHE_DIR` and `WORKER_LOCAL_MODEL_CACHE_DIR` before registration\n    - On failure, emit explicit remediation text (writable path, mount perms, fallback path) and exit non-zero unless fallback is enabled",
        "[x] Top-level fatal crash reporting (no silent death)\n    - Wrap startup/main loop with fatal exception handler that emits one structured `worker_fatal` event with phase, exception class, message, traceback, exit_code\n    - Ensure fatal paths always flush logs before process exit",
        "[x] Startup registration watchdog\n    - Add `WORKER_REGISTER_TIMEOUT_S` (default reasonable, e.g. 90s)\n    - If worker does not register with scheduler before timeout, emit `startup_timeout_unregistered` event and exit non-zero",
        "[x] Runtime blocked/stuck telemetry\n    - Emit per-task lifecycle events: `task_received`, `model_resolve_start/end`, `model_load_start/end`, `inference_start/end`, `task_completed|task_failed`\n    - Add long-running warnings (soft watchdog) for model load/inference phases with elapsed time and identifiers (run_id, function, model ref)",
        "[x] Orchestrator surfacing contract (coordination task)\n    - Document/implement worker event fields so gen-orchestrator can mark states like `launch_failed`, `startup_timeout`, `worker_fatal`, `task_stuck`\n    - Ensure \"waiting for worker connection\" paths include concrete reason + last known worker phase in logs/API where available",
        "[x] Tests\n    - Startup permission failure test: verifies explicit structured failure + non-zero exit\n    - Registration-timeout test: verifies watchdog event + exit\n    - Runtime stuck warning test: verifies long-running phase warning emission\n    - Fatal exception test: verifies `worker_fatal` event includes traceback metadata",
        "[x] Operator docs\n    - Add runbook section for diagnosing stuck workers (startup vs model download vs inference)\n    - Include expected event/log sequence and recommended actions for each failure mode"
      ],
      "completed": true
    },
    {
      "id": 77,
      "name": "Canonical Startup Phases Over gRPC (No /healthz Dependency)",
      "description": "Align worker startup/runtime observability with orchestrator policy:\n- After connect, worker->orchestrator gRPC telemetry is source-of-truth.\n- Worker startup should report canonical phases: `booting`, `models_downloading`, `pipeline_loading`, `ready`.\n- Provider diagnostics are for pre-connect/post-disconnect only.\n\nImportant non-goal:\n- Do not add a `/healthz` endpoint in worker images for orchestration health decisions. Health for scheduling should come from gRPC connectivity + phase/events.",
      "tasks": [
        "[ ] Emit canonical startup phases over existing worker event channel\n    - Map current detailed internal phases/events to canonical external states:\n      - process start/import/bootstrap -> `booting`\n      - model snapshot/materialization/download steps -> `models_downloading`\n      - pipeline construction + GPU load/warmup -> `pipeline_loading`\n      - post-registration and first-run capable -> `ready`\n    - Include phase timestamps and elapsed_ms",
        "[ ] Preserve detailed sub-phase diagnostics while publishing canonical state\n    - Keep current granular events (`manifest_loaded`, cache preflight, scheduler_connecting, etc.) for debugging\n    - Add canonical `startup_phase` field alongside detailed event_type",
        "[ ] Document and enforce contract with orchestrator\n    - Update worker docs/event schema so orchestrator can rely on canonical phases\n    - Ensure phase transitions are monotonic per process lifecycle (no regressions without restart)",
        "[ ] Explicitly document no `/healthz` orchestration dependency\n    - README/OPERATIONS note: scheduler health decisions must not depend on worker HTTP health checks"
      ],
      "completed": false
    },
    {
      "id": 78,
      "name": "Worker Protocol Stability: MAJOR.MINOR Versioning + Configurable Support Ranges (Cross-Repo)",
      "description": "Goal: keep the gen-worker <-> gen-orchestrator wire protocol stable so tenant images do not require rebuilds for normal platform iteration, while allowing orchestrator to support multiple older protocol versions for a period of time.\n\nPolicy:\n- Version only the worker wire protocol (not auth/JWT).\n- Auth remains separately enforced and is not part of wire version negotiation.\n- Additive changes only by default.\n- Breaking wire changes require MAJOR bump and explicit migration window.\n- Version model is protocol MAJOR.MINOR:\n  - MAJOR = breaking wire compatibility\n  - MINOR = backward-compatible additive change\n- Proto source layout rule:\n  - Same MAJOR: keep one proto package/schema and evolve additively.\n  - Breaking MAJOR (e.g. v1 -> v2): introduce separate versioned proto package/files and generated bindings for each supported MAJOR.\n\nRuntime model:\n- Handshake validation occurs after successful auth on worker registration.\n- Worker advertises `protocol_major` + `protocol_minor` in handshake.\n- Orchestrator accepts a configurable set of supported ranges (multiple majors, each with minor floor/ceiling), so old tenant images keep working until dropped.\n\nScope:\n- `~/cozy/gen-orchestrator` (proto source + server validation)\n- `~/cozy/python-gen-worker` (client/runtime handshake + compatibility checks)\n- Shared protobuf governance/docs/CI\n",
      "tasks": [
        "[x] Wire protocol policy doc (authoritative)\n    - Added in `gen-orchestrator/docs/worker_wire_protocol.md` with compatibility invariants and governance rules",
        "[x] Proto layout by MAJOR\n    - Documented: additive changes stay in `scheduler.v1`; breaking changes require separate versioned package/files",
        "[x] Add protocol version fields to handshake (wire)\n    - Added `protocol_major` + `protocol_minor` to `WorkerRegistration` in `proto/worker_scheduler.proto`\n    - Regenerated Go + Python stubs via `task proto`\n    - Validation remains post-auth in `ConnectWorker`",
        "[x] gen-orchestrator: configurable compatibility ranges\n    - Added `WORKER_SUPPORTED_PROTOCOL_RANGES` (default `1:0-9999`) with parser + matcher\n    - Worker connect now rejects unsupported versions with clear `unsupported_worker_protocol` failure details\n    - Added appconfig mapping: `workers.supported_protocol_ranges` -> env",
        "[x] gen-orchestrator: minor-version feature gating + fallback paths\n    - Added per-feature minor matrix in `pkg/scheduler/worker_protocol.go`\n    - Baseline feature support now starts at v1.0 for `release.models_by_function`\n    - Downgrade/fallback hooks remain in place for future minor-gated fields",
        "[x] python-gen-worker: advertise and enforce compatibility\n    - Added central runtime constants in `src/gen_worker/wire_protocol.py`\n    - Worker advertises protocol on every registration/heartbeat\n    - Worker detects protocol incompatibility errors and fails clearly instead of retrying blindly",
        "[ ] CI breaking-change guard on proto\n    - Pending: add automated proto breaking check + cross-repo generated-stub sync gate in CI",
        "[x] Cross-repo sync workflow\n    - Added canonical flow in `gen-orchestrator/docs/worker_wire_protocol.md`",
        "[x] Compatibility tests\n    - Added orchestrator protocol compatibility tests in `pkg/scheduler/worker_protocol_test.go`\n    - Added worker registration/version tests in `tests/test_worker_wire_protocol.py`",
        "[x] Rollout/migration playbook\n    - Added MAJOR/MINOR rollout guidance in `gen-orchestrator/docs/worker_wire_protocol.md`"
      ],
      "completed": false
    }
  ]
}
